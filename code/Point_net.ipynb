{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import vtk\n",
    "import os\n",
    "import numpy as np\n",
    "import itertools\n",
    "import math, random\n",
    "random.seed = 42\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "import scipy.spatial.distance\n",
    "# import plotly.graph_objects as go\n",
    "# import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#load 3d moded\n",
    "path = \"../input/modelnet10-princeton-3d-object-dataset/ModelNet10\"\n",
    "\n",
    "folders = [dir for dir in sorted(os.listdir(path)) if os.path.isdir(path/dir)]\n",
    "classes = {folder: i for i, folder in enumerate(folders)};\n",
    "classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Aneuxmodel_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, root = \"\", transform = None,train = False):\n",
    "\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.training = train\n",
    "        self.df = df\n",
    "        self.label = []\n",
    "        self.model_file = []\n",
    "        self.training_data_load()\n",
    "        self.my_device = \"cuda:0\"\n",
    "            \n",
    "            \n",
    "    def training_data_load(self):\n",
    "        self.label = []\n",
    "        self.model_file = []\n",
    "        all_imgs_dir = os.listdir(self.root)\n",
    "        transform_im= transforms.ToTensor()\n",
    "        for model in all_imgs_dir:\n",
    "                    \n",
    "            reader = vtk.vtkXMLPolyDataReader()\n",
    "            reader.SetFileName(model)\n",
    "            reader.Update()\n",
    "            polydata = reader.GetOutput()\n",
    "            points = polydata.GetPoints()\n",
    "            polygons = polydata.GetPolys()\n",
    "\n",
    "            self.label.append(points)\n",
    "        \n",
    "        return True\n",
    "        # self.org_imgs = np.array(self.org_imgs)\n",
    "        # self.total_imgs = torch.from_numpy(np.array(self.total_imgs)) \n",
    "        # self.label = torch.from_numpy(np.array(self.label))  \n",
    "        # return True\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        \"\"\" Returns one data pair (image and target caption). \"\"\"\n",
    "        image = self.org_imgs[index]\n",
    "        #print(type(image))\n",
    "        if self.transform is not None:      \n",
    "            image= self.transform(image)\n",
    "        return image,self.label[index]\n",
    "\n",
    "    def __len__(self):\n",
    "                                \n",
    "        return len(self.org_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PointNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from torch.nn import Sequential, Linear, ReLU,PointNet,PointNetLayer\n",
    "\n",
    "\n",
    "class PointNet(torch.nn.Module):\n",
    "    def __init__(self,dataset):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = PointNetLayer(3, 32)\n",
    "        self.conv2 = PointNetLayer(32, 32)\n",
    "        self.classifier = Linear(32, dataset.num_classes)\n",
    "\n",
    "    def forward(self,\n",
    "        pos: Tensor,\n",
    "        edge_index: Tensor,\n",
    "        batch: Tensor,\n",
    "    ) -> Tensor:\n",
    "\n",
    "        # Perform two-layers of message passing:\n",
    "        h = self.conv1(h=pos, pos=pos, edge_index=edge_index)\n",
    "        h = h.relu()\n",
    "        h = self.conv2(h=h, pos=pos, edge_index=edge_index)\n",
    "        h = h.relu()\n",
    "\n",
    "        # Global Pooling:\n",
    "        # h = global_max_pool(h, batch)  # [num_examples, hidden_channels]\n",
    "\n",
    "        # Classifier:\n",
    "        return self.classifier(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PointNet ++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
