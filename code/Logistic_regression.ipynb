{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "import sklearn as sklearn\n",
    "import scipy as scipy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_path = \"\"\n",
    "data = pd.read_csv(training_data_path)\n",
    "target_data = pd.read_csv(training_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameSelector(BaseEstimator):\n",
    "    \n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names= attribute_names\n",
    "        \n",
    "    def fit(self,X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "\n",
    "\n",
    "data_num = list(data)\n",
    "#from sklearn.experimental import enable_iterative_imputer\n",
    "#from sklearn.impute import IterativeImputer\n",
    "#imputer = IterativeImputer(max_iter = 30, random_state=0)\n",
    "num_pipeline= Pipeline([\n",
    "    ('selector', DataFrameSelector(data_num)),\n",
    "    ('imputer',SimpleImputer(strategy=\"mean\")),\n",
    "    ('stand_scalar',StandardScaler()),\n",
    "])\n",
    "\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "    (\"num_pipeline\",num_pipeline)\n",
    "])\n",
    "\n",
    "data_prepared = full_pipeline.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "target_data_copy = target_data[\"TARGET_deathRate\"].copy()\n",
    "\n",
    "data_copy = data.copy()\n",
    "data_copy[\"TARGET_deathRate\"] = target_data[\"TARGET_deathRate\"]\n",
    "\n",
    "train_set, test_set = train_test_split(data_copy , test_size= 0.2, random_state=42)\n",
    "\n",
    "train_set_target = train_set[\"TARGET_deathRate\"].copy()\n",
    "train_set.drop((\"TARGET_deathRate\"),axis=1,inplace=True)\n",
    "\n",
    "test_set_target = test_set[\"TARGET_deathRate\"].copy()\n",
    "test_set.drop((\"TARGET_deathRate\"),axis=1,inplace=True)\n",
    "\n",
    "test_prepared = full_pipeline.fit_transform(test_set)\n",
    "train_prepared = full_pipeline.fit_transform(train_set)\n",
    "\n",
    "print(test_prepared)\n",
    "print(test_set_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg=linear_model.LinearRegression()\n",
    "lin_reg.fit(train_prepared,train_set_target)\n",
    "\n",
    "data_predictions = lin_reg.predict(test_prepared)\n",
    "data_mse=mean_squared_error(data_predictions, test_set_target)\n",
    "data_rmse = np.sqrt(data_mse)\n",
    "print(\"OLS rmse:\",data_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso and Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "print(train_set_target)\n",
    "model_cv = linear_model.LassoCV(alphas=list(np.arange(0.01,20,0.01)), cv=5).fit(train_prepared,train_set_target)\n",
    "print(\"Lasso best alpha:\",model_cv.alpha_)\n",
    "las_reg_a = model_cv.alpha_\n",
    "#las_reg_a = search.best_params_['model__alpha']\n",
    "las_reg_a = 0.06\n",
    "\n",
    "\n",
    "lasso_reg = linear_model.Lasso(alpha=las_reg_a)\n",
    "lasso_reg.fit(train_prepared,train_set_target)\n",
    "\n",
    "lasso_data_predictions = lasso_reg.predict(test_prepared)\n",
    "lasso_data_mse=mean_squared_error(test_set_target, lasso_data_predictions)\n",
    "lasso_data_rmse = np.sqrt(lasso_data_mse)\n",
    "print(\"Lasso rmse:\", lasso_data_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odel_cv = linear_model.RidgeCV(alphas=list(np.arange(0.1,100,0.1)), cv=5).fit(train_prepared,train_set_target)\n",
    "print(\"Ridge best alpha:\",model_cv.alpha_)\n",
    "ridge_reg_a = model_cv.alpha_\n",
    "ridge_reg_a =19.7\n",
    "\n",
    "ridge_reg = linear_model.Ridge(alpha=ridge_reg_a)\n",
    "ridge_reg.fit(train_prepared,train_set_target)\n",
    "\n",
    "ridge_data_predictions = ridge_reg.predict(test_prepared)\n",
    "\n",
    "ridge_data_mse=mean_squared_error(test_set_target, ridge_data_predictions)\n",
    "ridge_data_rmse = np.sqrt(ridge_data_mse)\n",
    "print(\"Ridge rmse:\", ridge_data_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg.fit(train_prepared,train_set_target)\n",
    "\n",
    "logistic_data_predictions = logreg.predict(test_prepared)\n",
    "\n",
    "accuracy = logreg.score(test_set_target, logistic_data_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "forest_reg=RandomForestRegressor()\n",
    "#find estimator for random forest regression\n",
    "target_data_copy = target_data.copy()\n",
    "param_grid  = [{'n_estimators': [470,430],'max_features':[1,23, 27]}, \n",
    "               {'bootstrap': [False],'n_estimators':[30],'max_features':[8]}]\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,scoring='neg_mean_squared_error', verbose = 1)\n",
    "grid_search.fit(train_prepared,train_set_target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
