{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.hub import load_state_dict_from_url\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from torchvision.datasets import VisionDataset\n",
    "import os\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple MLP MODEL with 2 FCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLPModel, self).__init__()\n",
    "\n",
    "        # Define layers\n",
    "        self.Flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        #Adam\n",
    "        #self.optimizer = optim.Adam(self.parameters(), lr=0.001) #weight decay\n",
    "        self.optimizer = optim.SGD(self.parameters(), lr=0.001, momentum=0.9)\n",
    "        self.running_loss = 0\n",
    "        self.loss = None\n",
    "        self.losses = []\n",
    "\n",
    "    def forward(self, x, target =None):\n",
    "        # Forward pass\n",
    "        x = self.Flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "    def fit(self, x, targets):\n",
    "        #train/optimize/fit\n",
    "        preds = self.forward(x)\n",
    "        self.loss = self.loss_fn(preds, targets)\n",
    "        self.loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        loss_item = self.loss.item()\n",
    "        return loss_item\n",
    "\n",
    "\n",
    "    def reset_loss(self, value):\n",
    "        self.running_loss = value\n",
    "        self.losses = []\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN MODEL 3 CONV & 3 FCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, input_size,input_channel, kernel_size, middle_channel, output_channel,hidden_input,output_size,padding = 0, Drop = 0.1):\n",
    "        super(CNNModel, self).__init__()\n",
    "        reduce_size = 0\n",
    "        size = input_size\n",
    "        if padding == 0:\n",
    "            reduce_size = size - kernel_size +1\n",
    "            reduce_size = reduce_size/2\n",
    "            reduce_size = reduce_size - kernel_size +1\n",
    "            reduce_size = int(reduce_size/2)\n",
    "        else:\n",
    "            reduce_size = int(size/4)\n",
    "        # Define layers\n",
    "        self.Drop = Drop\n",
    "        self.Dropout = nn.Dropout(p=self.Drop)\n",
    "        self.Conv2d1 = nn.Conv2d(in_channels=input_channel,out_channels=middle_channel, kernel_size=kernel_size,padding = padding)\n",
    "        self.ReLU = nn.ReLU()\n",
    "        self.MaxPool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Conv2d2 = nn.Conv2d(in_channels=middle_channel,out_channels=output_channel, kernel_size=kernel_size,padding = padding)\n",
    "        self.Flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(output_channel*reduce_size*reduce_size,hidden_input)\n",
    "        self.fc2 = nn.Linear(hidden_input,output_size)\n",
    "        \n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        #self.optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "        self.optimizer = optim.SGD(self.parameters(), lr=0.001,momentum=0.9) \n",
    "        self.running_loss = 0\n",
    "        self.loss = None\n",
    "        self.losses = []\n",
    "        self.dropout_enable = False\n",
    "        \n",
    "    def forward(self, x, target = None):\n",
    "        #x shape: (batch_size, h, w, channels)\n",
    "        #output shape: (batch_size, output_size)\n",
    "        # Forward pass\n",
    "        #if self.Drop:\n",
    "        #    x = self.Dropout(x)\n",
    "            \n",
    "        x = self.Conv2d1(x)\n",
    "        x = self.ReLU(x)\n",
    "        \n",
    "        if self.dropout_enable:\n",
    "            x = self.Dropout(x)\n",
    "            \n",
    "        x = self.MaxPool2d(x)\n",
    "        x = self.Conv2d2(x)\n",
    "        x = self.ReLU(x)\n",
    "        x = self.MaxPool2d(x)\n",
    "        x = self.Flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.ReLU(x)\n",
    "        if self.dropout_enable:\n",
    "            x = self.Dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        #update\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "    def fit(self, x, targets):\n",
    "        #train/optimize/fit\n",
    "        preds = self.forward(x)\n",
    "        self.loss = self.loss_fn(preds, targets)\n",
    "        self.loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        loss_item = self.loss.item()\n",
    "        return loss_item\n",
    "\n",
    "\n",
    "    def reset_loss(self):\n",
    "        self.running_loss = 0\n",
    "        self.loss = None\n",
    "        return"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
